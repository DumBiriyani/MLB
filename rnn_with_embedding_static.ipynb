{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# # import tensorflow as tf\n",
    "from tensorflow.python.keras.layers import Input, LSTM, Dense, Masking, Embedding, concatenate\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./processed_data/dynamic_feats.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Feature List__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_league_cols = [\"nba_season_flag\", \"nfl_season_flag\", \"nhl_season_flag\"]\n",
    "\n",
    "common_features = [\"year\",\n",
    "                    \"DayofWeek\",\n",
    "                    \"HomeTeamGameNumber\",\n",
    "                    \"VisitingTeamGameNumber\",\n",
    "                    \"park_age\",\n",
    "                    \"Month\",\n",
    "                    \"DayofMonth\",\n",
    "                    \"DayFlag\",\n",
    "                    \"NonRegular_ParkFlag\",\n",
    "                    \"StadiumCapacity\"]+\\\n",
    "                    [\"home_payroll\", \"home_top_salary\", \"visiting_payroll\", \"visiting_top_salary\"] +\\\n",
    "                    other_league_cols\n",
    "\n",
    "# Only used in static Models\n",
    "prev_season_features = [\"HomeAttendance_last_year\",\n",
    "                        \"VisitingAttendance_last_year\",\n",
    "                        \"combo_Attendance_last_year\",\n",
    "                        \"Homewin_rate_last_year\",\n",
    "                        \"Homeday_league_rank_last_year\",\n",
    "                        \"HomeTeamOffense_Homeruns_last_year\",\n",
    "                        \"HomeTeamOffense_Strickouts_last_year\",\n",
    "                        \"HomeTeamPitchers_TeamEarnedRuns_last_year\",\n",
    "                        \"Visitingwin_rate_last_year\",\n",
    "                        \"Visitingday_league_rank_last_year\",\n",
    "                        \"VisitingTeamOffense_Homeruns_last_year\",\n",
    "                        \"VisitingTeamOffense_Strickouts_last_year\",\n",
    "                        \"VisitingTeamPitchers_TeamEarnedRuns_last_year\",\n",
    "                        \"HomeTeamScore_last_year\",\n",
    "                        \"VistingTeamScore_last_year\"]\n",
    "\n",
    "rolling_feats = ['HomeTeamOffense_Homeruns-1',\n",
    "                'HomeTeamOffense_Homeruns-2',\n",
    "                'HomeTeamOffense_Homeruns-3',\n",
    "                'HomeTeamOffense_Homeruns-4',\n",
    "                'HomeTeamOffense_Homeruns-5',\n",
    "                'HomeTeamOffense_Homeruns-6',\n",
    "                'HomeTeamOffense_Homeruns-7',\n",
    "                'HomeTeamOffense_Strickouts-1',\n",
    "                'HomeTeamOffense_Strickouts-2',\n",
    "                'HomeTeamOffense_Strickouts-3',\n",
    "                'HomeTeamOffense_Strickouts-4',\n",
    "                'HomeTeamOffense_Strickouts-5',\n",
    "                'HomeTeamOffense_Strickouts-6',\n",
    "                'HomeTeamOffense_Strickouts-7',\n",
    "                'HomeTeamPitchers_TeamEarnedRuns-1',\n",
    "                'HomeTeamPitchers_TeamEarnedRuns-2',\n",
    "                'HomeTeamPitchers_TeamEarnedRuns-3',\n",
    "                'HomeTeamPitchers_TeamEarnedRuns-4',\n",
    "                'HomeTeamPitchers_TeamEarnedRuns-5',\n",
    "                'HomeTeamPitchers_TeamEarnedRuns-6',\n",
    "                'HomeTeamPitchers_TeamEarnedRuns-7']\n",
    "\n",
    "prev_match_features = ['Homewin_rate', 'Homeday_league_rank']\n",
    "\n",
    "categorical_feat_cols = [\"VisitingTeam\",\n",
    "                        \"VisitingTeamLeague\",\n",
    "                        \"HomeTeam\",\n",
    "                        \"HomeTeamLeague\",\n",
    "                        \"BallParkID\"]\n",
    "\n",
    "continuous_feat_cols = common_features + rolling_feats + prev_match_features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Constants and Helper Functions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_COL = \"AttendanceRatio\"\n",
    "\n",
    "# 84 games at most in a season, 22 seasons\n",
    "LEN_TS = 84*22\n",
    "NUM_CONT_FEATURES = len(continuous_feat_cols)\n",
    "NUM_CAT_FEATURES = len(categorical_feat_cols)\n",
    "VALIDATION_YEARS = [2022]\n",
    "\n",
    "ranking_map_cols = [\"Date\",\"Team\"]\n",
    "ranking_info_cols = [\"total_wins\",\"day_league_rank\",\"win_rate\"]\n",
    "\n",
    "def pad_with_bfill(arr_list, max_len):\n",
    "    # Pad each array with backfill to the length of the longest array\n",
    "    padded_arr_list = []\n",
    "    for arr in arr_list:\n",
    "        padded_arr = np.pad(arr, pad_width=[(max_len - len(arr), 0),(0,0),(0,0)], mode='edge')\n",
    "        padded_arr_list.append(padded_arr)\n",
    "    return padded_arr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "val_idx = df[\"year\"].isin(VALIDATION_YEARS)\n",
    "train_idx = ~val_idx\n",
    "\n",
    "for col in continuous_feat_cols+[TARGET_COL]:\n",
    "    norm_arr_train = df.loc[train_idx, col].values.reshape(-1,1)\n",
    "    norm_arr_val = df.loc[val_idx, col].values.reshape(-1,1)\n",
    "    label_normalizer = MinMaxScaler().fit(norm_arr_train)\n",
    "    df.loc[train_idx, col] = label_normalizer.transform(norm_arr_train)\n",
    "    df.loc[val_idx, col] = label_normalizer.transform(norm_arr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# preprocess categorical columns\n",
    "encoders = []\n",
    "\n",
    "for col in categorical_feat_cols:\n",
    "    encoder = LabelEncoder()\n",
    "    data_cat = df[col].fillna('N/A').astype(str)\n",
    "    df[col+\"_encoded\"] = encoder.fit_transform(data_cat)\n",
    "    encoders.append(encoder)\n",
    "\n",
    "categorical_feat_cols = [col+\"_encoded\" for col in categorical_feat_cols]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "### Reshaping data for RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = []\n",
    "y_train = []\n",
    "x_val = []\n",
    "y_val = []\n",
    "x_train_cat = []\n",
    "x_val_cat = []\n",
    "\n",
    "num_teams = df[\"HomeTeam\"].nunique()\n",
    "\n",
    "for team, team_df in df.groupby([\"HomeTeam\"]):\n",
    "    team_train_df = team_df.loc[train_idx,:]\n",
    "    team_val_df = team_df.loc[val_idx,:]\n",
    "    train_games = len(team_train_df)\n",
    "    val_games = len(team_val_df)\n",
    "    train_features = team_train_df.loc[:, continuous_feat_cols\n",
    "                                ].values.reshape(train_games, NUM_CONT_FEATURES, 1)\n",
    "    train_labels = team_train_df.loc[:, TARGET_COL\n",
    "                               ].values.reshape(train_games, 1)\n",
    "    val_features = team_val_df.loc[:, continuous_feat_cols\n",
    "                                ].values.reshape(val_games, NUM_CONT_FEATURES, 1)\n",
    "    val_labels = team_val_df.loc[:, \n",
    "                           TARGET_COL].values.reshape(val_games, 1)\n",
    "    \n",
    "    # Categorical Features\n",
    "    train_cat_features = team_train_df.loc[:, categorical_feat_cols\n",
    "                                ].values.reshape(train_games, NUM_CAT_FEATURES, 1)\n",
    "    val_cat_features = team_val_df.loc[:, categorical_feat_cols\n",
    "                                    ].values.reshape(val_games, NUM_CAT_FEATURES, 1)\n",
    "    \n",
    "    x_train.append(train_features)\n",
    "    y_train.append(train_labels)\n",
    "    x_val.append(val_features)\n",
    "    y_val.append(val_labels)\n",
    "    x_train_cat.append(train_cat_features)\n",
    "    x_val_cat.append(val_cat_features)\n",
    "\n",
    "len_ts_train = df.loc[train_idx,:].groupby(\"HomeTeam\")[\"HomeTeamGameNumber\"].size().max()\n",
    "len_ts_val = df.loc[val_idx,:].groupby(\"HomeTeam\")[\"HomeTeamGameNumber\"].size().max()\n",
    "\n",
    "x_train = pad_sequences(x_train, value=-1, maxlen=len_ts_train).reshape(len_ts_train, num_teams, NUM_CONT_FEATURES, 1)\n",
    "y_train = pad_sequences(y_train, value=-1, maxlen=len_ts_train).reshape(len_ts_train, num_teams, 1)\n",
    "\n",
    "x_val = pad_sequences(x_val, value=-1, maxlen=len_ts_val).reshape(len_ts_val, num_teams, NUM_CONT_FEATURES, 1)\n",
    "y_val = pad_sequences(y_val, value=-1, maxlen=len_ts_val).reshape(len_ts_val, num_teams, 1)\n",
    "\n",
    "x_train_cat = np.array(pad_with_bfill(x_train_cat, len_ts_train))\n",
    "x_val_cat = np.array(pad_with_bfill(x_val_cat, len_ts_val))\n",
    "\n",
    "x_train_cat = [arr.reshape(len_ts_train, num_teams) for arr in np.split(x_train_cat, NUM_CAT_FEATURES, axis=2)]\n",
    "x_val_cat = [arr.reshape(len_ts_val, num_teams) for arr in np.split(x_val_cat, NUM_CAT_FEATURES, axis=2)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Model\n",
    "- Implement Batch Normalization! --> Data Leakage otherwise\n",
    "    - Len of TS: 84*20 (number of games per season)*(number of seasons)\n",
    "    - Number of TS: 30 (number of teams)\n",
    "    - Number of Features: 15\n",
    "- Add masking: DONE\n",
    "- Perform pre-padding: DONE\n",
    "- Add normalization: DONE but not batch?!\n",
    "- Target Variable change: Use %age attendance instead of absolute capacity --> DONE but using different logic\n",
    "- Add early stopping: DONE\n",
    "- Add embeddings DONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for Training\n",
    "EPOCHS = 50\n",
    "MIN_DELTA = 0.001\n",
    "PATIENCE = 3\n",
    "\n",
    "# add an embedding layer for the categorical inputs\n",
    "categorical_embedding_size = 10\n",
    "\n",
    "# Define the input shape\n",
    "cont_input_shape = x_train.shape[1:3]\n",
    "# cat_input_shape = x_train_cat.shape[1:3]\n",
    "output_shape = 1\n",
    "\n",
    "early_stopper = EarlyStopping(monitor='val_loss',\n",
    "                              mode='min',\n",
    "                              min_delta=MIN_DELTA,\n",
    "                              patience=PATIENCE)\n",
    "\n",
    "## For every categorical variable we have it's own input\n",
    "categorical_inputs = [Input(shape=(num_teams, ),\n",
    "                      name='cat_' + str(i + 1)) for i in range(NUM_CAT_FEATURES)]\n",
    "masked_categorical_inputs = [Masking(input_shape=(num_teams, ))(inp) for inp in categorical_inputs]\n",
    "\n",
    "## Shared embedding layer\n",
    "cat_embedding = Embedding(input_dim=np.max(x_train_cat) + 1,\n",
    "                                output_dim=categorical_embedding_size,\n",
    "                                input_length=len_ts_train)\n",
    "\n",
    "## Repeat this for every categorical column\n",
    "cat_embeddings = [cat_embedding(inp) for inp in masked_categorical_inputs]\n",
    "\n",
    "time_series_input = Input(shape=cont_input_shape)\n",
    "masked_ts_input = Masking(input_shape=cont_input_shape)(time_series_input)\n",
    "\n",
    "## Concatenate the time series input and the embedding outputs\n",
    "x = concatenate([masked_ts_input] + cat_embeddings, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "54/54 [==============================] - 12s 86ms/step - loss: 96120856379392.0000 - val_loss: 0.0133\n",
      "Epoch 2/50\n",
      "54/54 [==============================] - 4s 76ms/step - loss: 97101107167232.0000 - val_loss: 0.0126\n",
      "Epoch 3/50\n",
      "54/54 [==============================] - 4s 80ms/step - loss: 884541333962752.0000 - val_loss: 0.0124\n",
      "Epoch 4/50\n",
      "54/54 [==============================] - 4s 79ms/step - loss: 120572994387968.0000 - val_loss: 2.7067\n"
     ]
    }
   ],
   "source": [
    "x = LSTM(128,\n",
    "    activation=\"relu\",\n",
    "    return_sequences=True,\n",
    "    dropout=0.2)(x)\n",
    "\n",
    "x = LSTM(64,\n",
    "    activation=\"relu\",\n",
    "    return_sequences=True,\n",
    "    dropout=0.2)(x)\n",
    "\n",
    "x = LSTM(64,\n",
    "    activation=\"relu\",\n",
    "    return_sequences=True,\n",
    "    dropout=0.2)(x)\n",
    "\n",
    "x = Dense(output_shape)(x)\n",
    "\n",
    "model = Model(inputs=[time_series_input]+categorical_inputs, outputs=x)\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model with your pandas DataFrame\n",
    "model.fit([x_train]+x_train_cat,\n",
    "          y_train,\n",
    "          epochs=50,\n",
    "          batch_size=32,\n",
    "          validation_data=([x_val]+x_val_cat, y_val),\n",
    "          callbacks=[early_stopper])\n",
    "\n",
    "# Predict the next season (84 games) for all 30 teams (a single time series) using the trained model\n",
    "predictions = model.predict([x_val]+x_val_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38644965290582506, 1689474218465500.8, 2.7251631336780657)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error, mean_squared_error\n",
    "\n",
    "y_pred = predictions[1:,:].reshape(81*30,)\n",
    "y_true = y_val[1:,:].reshape(81*30,)\n",
    "mean_absolute_error(y_true, y_pred), mean_absolute_percentage_error(y_true, y_pred), mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
